                     Download from finelybook www.finelybook.com


                                                                                           CHAPTER 3
                                                                            Classification




In Chapter 1 we mentioned that the most common supervised learning tasks are
regression (predicting values) and classification (predicting classes). In Chapter 2 we
explored a regression task, predicting housing values, using various algorithms such
as Linear Regression, Decision Trees, and Random Forests (which will be explained
in further detail in later chapters). Now we will turn our attention to classification
systems.

MNIST
In this chapter, we will be using the MNIST dataset, which is a set of 70,000 small
images of digits handwritten by high school students and employees of the US Cen‐
sus Bureau. Each image is labeled with the digit it represents. This set has been stud‐
ied so much that it is often called the “Hello World” of Machine Learning: whenever
people come up with a new classification algorithm, they are curious to see how it
will perform on MNIST. Whenever someone learns Machine Learning, sooner or
later they tackle MNIST.
Scikit-Learn provides many helper functions to download popular datasets. MNIST is
one of them. The following code fetches the MNIST dataset:1
    >>> from sklearn.datasets import fetch_mldata
    >>> mnist = fetch_mldata('MNIST original')
    >>> mnist
    {'COL_NAMES': ['label', 'data'],
     'DESCR': 'mldata.org dataset: mnist-original',
     'data': array([[0, 0, 0, ..., 0, 0, 0],
            [0, 0, 0, ..., 0, 0, 0],



1 By default Scikit-Learn caches downloaded datasets in a directory called $HOME/scikit_learn_data.



                                                                                                      79
                           Download from finelybook www.finelybook.com
                 [0, 0, 0, ...,        0, 0, 0],
                 ...,
                 [0, 0, 0, ...,        0, 0,   0],
                 [0, 0, 0, ...,        0, 0,   0],
                 [0, 0, 0, ...,        0, 0,   0]], dtype=uint8),
          'target': array([ 0.,         0.,    0., ..., 9., 9.,     9.])}
Datasets loaded by Scikit-Learn generally have a similar dictionary structure includ‐
ing:

     • A DESCR key describing the dataset
     • A data key containing an array with one row per instance and one column per
       feature
     • A target key containing an array with the labels

Let’s look at these arrays:
      >>> X, y = mnist["data"], mnist["target"]
      >>> X.shape
      (70000, 784)
      >>> y.shape
      (70000,)
There are 70,000 images, and each image has 784 features. This is because each image
is 28×28 pixels, and each feature simply represents one pixel’s intensity, from 0
(white) to 255 (black). Let’s take a peek at one digit from the dataset. All you need to
do is grab an instance’s feature vector, reshape it to a 28×28 array, and display it using
Matplotlib’s imshow() function:
      %matplotlib inline
      import matplotlib
      import matplotlib.pyplot as plt

      some_digit = X[36000]
      some_digit_image = some_digit.reshape(28, 28)

      plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,
                 interpolation="nearest")
      plt.axis("off")
      plt.show()




This looks like a 5, and indeed that’s what the label tells us:


80    |    Chapter 3: Classification
                      Download from finelybook www.finelybook.com
    >>> y[36000]
    5.0
Figure 3-1 shows a few more images from the MNIST dataset to give you a feel for
the complexity of the classification task.




Figure 3-1. A few digits from the MNIST dataset

But wait! You should always create a test set and set it aside before inspecting the data
closely. The MNIST dataset is actually already split into a training set (the first 60,000
images) and a test set (the last 10,000 images):
    X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
Let’s also shuffle the training set; this will guarantee that all cross-validation folds will
be similar (you don’t want one fold to be missing some digits). Moreover, some learn‐
ing algorithms are sensitive to the order of the training instances, and they perform
poorly if they get many similar instances in a row. Shuffling the dataset ensures that
this won’t happen:2



2 Shuffling may be a bad idea in some contexts—for example, if you are working on time series data (such as
  stock market prices or weather conditions). We will explore this in the next chapters.



                                                                                                MNIST   |     81
                         Download from finelybook www.finelybook.com
     import numpy as np

     shuffle_index = np.random.permutation(60000)
     X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]


Training a Binary Classifier
Let’s simplify the problem for now and only try to identify one digit—for example,
the number 5. This “5-detector” will be an example of a binary classifier, capable of
distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for
this classification task:
     y_train_5 = (y_train == 5)       # True for all 5s, False for all other digits.
     y_test_5 = (y_test == 5)
Okay, now let’s pick a classifier and train it. A good place to start is with a Stochastic
Gradient Descent (SGD) classifier, using Scikit-Learn’s SGDClassifier class. This clas‐
sifier has the advantage of being capable of handling very large datasets efficiently.
This is in part because SGD deals with training instances independently, one at a time
(which also makes SGD well suited for online learning), as we will see later. Let’s create
an SGDClassifier and train it on the whole training set:
     from sklearn.linear_model import SGDClassifier

     sgd_clf = SGDClassifier(random_state=42)
     sgd_clf.fit(X_train, y_train_5)


                      The SGDClassifier relies on randomness during training (hence
                      the name “stochastic”). If you want reproducible results, you
                      should set the random_state parameter.



Now you can use it to detect images of the number 5:
     >>> sgd_clf.predict([some_digit])
     array([ True], dtype=bool)

The classifier guesses that this image represents a 5 (True). Looks like it guessed right
in this particular case! Now, let’s evaluate this model’s performance.

Performance Measures
Evaluating a classifier is often significantly trickier than evaluating a regressor, so we
will spend a large part of this chapter on this topic. There are many performance
measures available, so grab another coffee and get ready to learn many new concepts
and acronyms!



82   |   Chapter 3: Classification
